{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries for pre-processing\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_max(df, col):\n",
    "    '''Get the maximum value of a given column'''\n",
    "    return df[col].max()\n",
    "\n",
    "def get_col_min(df, col):\n",
    "    '''Get the minimum value of a given column'''\n",
    "    return df[col].min()\n",
    "\n",
    "def get_col_count(df, col):\n",
    "    '''Get the number of elements of a given column'''\n",
    "    return df[col].count()\n",
    "\n",
    "def get_col_avg(df, col):\n",
    "    '''Get the average value of a given column'''\n",
    "    return df[col].mean()\n",
    "\n",
    "def get_col_std(df, col):\n",
    "    '''Get the standar deviation value of a given column'''\n",
    "    return df[col].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(df, column, date_format='%y%m%d'):\n",
    "    '''Convert the given column containg dates in the given format\n",
    "    to the standard date format and type'''\n",
    "    copy_df = df.copy()\n",
    "    copy_df[column] = pd.to_datetime(copy_df[column], format=date_format)\n",
    "\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(df, column, options_list):\n",
    "    '''Encode the given column of the given dataframe.\n",
    "    All column values should be present in the options_list.'''\n",
    "    copy_df = df.copy()\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(options_list)\n",
    "    copy_df[column] = le.transform(copy_df[column])\n",
    "    \n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df, columns):\n",
    "    '''Normalize the given columns for range between [0, 1]'''\n",
    "    for col in columns:\n",
    "        col_min = get_col_min(df, col)\n",
    "        col_max = get_col_max(df, col)\n",
    "        \n",
    "        df[col] = (df[col] - col_min)/\\\n",
    "                    (col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_correlation(df):\n",
    "    '''Get the correlation between the dataframe features'''\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    # Set up the matplotlib figure\n",
    "    plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    ax = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "                     square=True, linewidths=.1, cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    y_lim = ax.get_ylim();\n",
    "    ax.set_ylim(np.ceil(y_lim[0]), np.floor(y_lim[1]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_two_cols(df, col1, col2):\n",
    "    '''Get a scatterplot for the given two columns'''\n",
    "    # Set up the matplotlib figure\n",
    "    plt.subplots(figsize=(11, 9))\n",
    "    \n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.scatterplot(data=df, x=col1, y=col2,\n",
    "                    hue='status',palette=cmap, sizes=(47,47))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_summary(dataset):\n",
    "    '''Get a null summary display'''\n",
    "    display(dataset.isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nulls(dataset, threshold=0.7):\n",
    "    '''Clean nulls from the given table.\n",
    "    If the nulls in a column are higher than the given threshold the entire column is deleted.\n",
    "    If the nulls in a row are higher than the row, the row is also deleted.\n",
    "    The threshold is a value between 0 and 1'''\n",
    "    #Dropping columns with missing value rate higher than threshold\n",
    "    dataset = dataset[dataset.columns[dataset.isnull().mean() < threshold]]\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    dataset = dataset.loc[dataset.isnull().mean(axis=1) < threshold]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_imputation(dataset, replacer=None):\n",
    "    '''When null values exist, set them using the median of the colum,\n",
    "    or a replacer, if one was given'''\n",
    "    dataset = dataset.fillna(replacer if replacer else dataset.median())\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_imputation(dataset, column_name, replacer=None):\n",
    "    '''Replace the inexistent values of the given column with the given replacer.\n",
    "    If None replacer was ginve, use the column maximum value'''\n",
    "    #Max fill function for categorical columns\n",
    "    dataset[column_name].fillna(replacer if replacer else \\\n",
    "                                dataset[column_name].value_counts()\n",
    "                                                    .idxmax(),\n",
    "                                inplace=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_to_drop_std(dataset, column, mult_factor=3):\n",
    "    '''Display the rows that will be dropped using the std approach'''\n",
    "    upper_lim = dataset[column].mean() + dataset[column].std() * mult_factor\n",
    "    lower_lim = dataset[column].mean() - dataset[column].std() * mult_factor\n",
    "\n",
    "    display(dataset[(dataset[column] >= upper_lim) & (dataset[column] <= lower_lim)])\n",
    "\n",
    "def drop_outliers_std(dataset, column, mult_factor=3):\n",
    "    '''Drop the outlier rows with standard deviation'''\n",
    "    upper_lim = dataset[column].mean() + dataset[column].std() * mult_factor\n",
    "    lower_lim = dataset[column].mean() - dataset[column].std() * mult_factor\n",
    "\n",
    "    return dataset[(dataset[column] < upper_lim) & (dataset[column] > lower_lim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_to_drop_percentile(dataset, column):\n",
    "    '''Display the rows that will be dropped with Percentiles approach'''\n",
    "    upper_lim = dataset[column].quantile(.95)\n",
    "    lower_lim = dataset[column].quantile(.05)\n",
    "\n",
    "    display(dataset[(dataset[column] >= upper_lim) & (dataset[column] <= lower_lim)])\n",
    "\n",
    "def drop_outliers_percentile(dataset, column):\n",
    "    '''Drop the outlier rows with Percentiles approach'''\n",
    "    upper_lim = dataset[column].quantile(.95)\n",
    "    lower_lim = dataset[column].quantile(.05)\n",
    "\n",
    "    data = dataset[(dataset[column] < upper_lim) & (dataset[column] > lower_lim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_binning(dataset):\n",
    "    # TODO\n",
    "    # https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_binning(dataset):\n",
    "    # TODO\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### For a first simpler approach, we will only use the 'loan' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ::: Tables Scheme :::\n",
      "\n",
      "\n",
      "\t LOAN TABLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edgarcarneiro/Documents/University/feup-ecac/project-competition/env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5314</td>\n",
       "      <td>1787</td>\n",
       "      <td>930705</td>\n",
       "      <td>96396</td>\n",
       "      <td>12</td>\n",
       "      <td>8033</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5316</td>\n",
       "      <td>1801</td>\n",
       "      <td>930711</td>\n",
       "      <td>165960</td>\n",
       "      <td>36</td>\n",
       "      <td>4610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6863</td>\n",
       "      <td>9188</td>\n",
       "      <td>930728</td>\n",
       "      <td>127080</td>\n",
       "      <td>60</td>\n",
       "      <td>2118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5325</td>\n",
       "      <td>1843</td>\n",
       "      <td>930803</td>\n",
       "      <td>105804</td>\n",
       "      <td>36</td>\n",
       "      <td>2939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7240</td>\n",
       "      <td>11013</td>\n",
       "      <td>930906</td>\n",
       "      <td>274740</td>\n",
       "      <td>60</td>\n",
       "      <td>4579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id  account_id    date  amount  duration  payments  status\n",
       "0     5314        1787  930705   96396        12      8033      -1\n",
       "1     5316        1801  930711  165960        36      4610       1\n",
       "2     6863        9188  930728  127080        60      2118       1\n",
       "3     5325        1843  930803  105804        36      2939       1\n",
       "4     7240       11013  930906  274740        60      4579       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t ACCOUNT TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>district_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>55</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>930101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3818</td>\n",
       "      <td>74</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>930101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>704</td>\n",
       "      <td>55</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>930101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2378</td>\n",
       "      <td>16</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>930101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2632</td>\n",
       "      <td>24</td>\n",
       "      <td>monthly issuance</td>\n",
       "      <td>930102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  district_id         frequency    date\n",
       "0         576           55  monthly issuance  930101\n",
       "1        3818           74  monthly issuance  930101\n",
       "2         704           55  monthly issuance  930101\n",
       "3        2378           16  monthly issuance  930101\n",
       "4        2632           24  monthly issuance  930102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t DISPOSITION TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disp_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>DISPONENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>OWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>DISPONENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disp_id  client_id  account_id       type\n",
       "0        1          1           1      OWNER\n",
       "1        2          2           2      OWNER\n",
       "2        3          3           2  DISPONENT\n",
       "3        4          4           3      OWNER\n",
       "4        5          5           3  DISPONENT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t CREDIT CARD TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>disp_id</th>\n",
       "      <th>type</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>9285</td>\n",
       "      <td>classic</td>\n",
       "      <td>931107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>588</td>\n",
       "      <td>classic</td>\n",
       "      <td>940119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>4915</td>\n",
       "      <td>classic</td>\n",
       "      <td>940205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>439</td>\n",
       "      <td>classic</td>\n",
       "      <td>940208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>577</td>\n",
       "      <td>3687</td>\n",
       "      <td>classic</td>\n",
       "      <td>940215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  disp_id     type  issued\n",
       "0     1005     9285  classic  931107\n",
       "1      104      588  classic  940119\n",
       "2      747     4915  classic  940205\n",
       "3       70      439  classic  940208\n",
       "4      577     3687  classic  940215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tTRANSACTIONS TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>operation</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>bank</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1548749</td>\n",
       "      <td>5270</td>\n",
       "      <td>930113</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1548750</td>\n",
       "      <td>5270</td>\n",
       "      <td>930114</td>\n",
       "      <td>credit</td>\n",
       "      <td>collection from another bank</td>\n",
       "      <td>44749.0</td>\n",
       "      <td>45549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IJ</td>\n",
       "      <td>80269753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3393738</td>\n",
       "      <td>11265</td>\n",
       "      <td>930114</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3122924</td>\n",
       "      <td>10364</td>\n",
       "      <td>930117</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1121963</td>\n",
       "      <td>3834</td>\n",
       "      <td>930119</td>\n",
       "      <td>credit</td>\n",
       "      <td>credit in cash</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_id  account_id    date    type                     operation  \\\n",
       "0   1548749        5270  930113  credit                credit in cash   \n",
       "1   1548750        5270  930114  credit  collection from another bank   \n",
       "2   3393738       11265  930114  credit                credit in cash   \n",
       "3   3122924       10364  930117  credit                credit in cash   \n",
       "4   1121963        3834  930119  credit                credit in cash   \n",
       "\n",
       "    amount  balance k_symbol bank     account  \n",
       "0    800.0    800.0      NaN  NaN         NaN  \n",
       "1  44749.0  45549.0      NaN   IJ  80269753.0  \n",
       "2   1000.0   1000.0      NaN  NaN         NaN  \n",
       "3   1100.0   1100.0      NaN  NaN         NaN  \n",
       "4    700.0    700.0      NaN  NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the different train tables\n",
    "loan_df = utils.read_csv_to_df('competition_dataset/loan_train.csv', delimiter=';')\n",
    "account_df = utils.read_csv_to_df('competition_dataset/account.csv', delimiter=';')\n",
    "disp_df = utils.read_csv_to_df('competition_dataset/disp.csv', delimiter=';')\n",
    "card_df = utils.read_csv_to_df('competition_dataset/card_train.csv', delimiter=';')\n",
    "trans_df = utils.read_csv_to_df('competition_dataset/trans_train.csv', delimiter=';')\n",
    "\n",
    "# Loading the test tables\n",
    "loan_test_df = utils.read_csv_to_df('competition_dataset/loan_test.csv', delimiter=';')\n",
    "card_test_df = utils.read_csv_to_df('competition_dataset/card_test.csv', delimiter=';')\n",
    "trans_test_df = utils.read_csv_to_df('competition_dataset/trans_test.csv', delimiter=';')\n",
    "\n",
    "\n",
    "print(' ::: Tables Scheme :::')\n",
    "print('\\n\\n\\t LOAN TABLE')\n",
    "display(loan_df.head())\n",
    "print('\\n\\n\\t ACCOUNT TABLE')\n",
    "display(account_df.head())\n",
    "print('\\n\\n\\t DISPOSITION TABLE')\n",
    "display(disp_df.head())\n",
    "print('\\n\\n\\t CREDIT CARD TABLE')\n",
    "display(card_df.head())\n",
    "print('\\n\\n\\tTRANSACTIONS TABLE')\n",
    "display(trans_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual pre processement of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_loans(loans_df, debug=False):\n",
    "    '''Pre process the loan table'''\n",
    "    if debug:\n",
    "        print(' > Raw loan table representation')\n",
    "        display(loans_df)\n",
    "        print(' > Raw loan table correlations')\n",
    "        get_df_correlation(loans_df)\n",
    "        \n",
    "    processed_df = convert_date(loan_df, 'date')\n",
    "    \n",
    "    # As there is a correlation between amount, duration & payments\n",
    "    if debug:\n",
    "        print(' > There is naturally a correlation between the amount, duration and payments columns,'+\n",
    "              'since amount = columns * payments')\n",
    "        scatterplot_two_cols(processed_df, 'amount', 'duration')\n",
    "        scatterplot_two_cols(processed_df, 'amount', 'payments')\n",
    "        print(' > Natural correlations, since the larger the amount the larger the monthly payment or the duration.')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_account(accounts_df, debug=False):\n",
    "    '''Pre process the accounts table'''\n",
    "    if debug:\n",
    "        print(' > Raw accounts table representation')\n",
    "        display(accounts_df)\n",
    "        print(' > Raw accounts table correlations')\n",
    "        get_df_correlation(accounts_df)\n",
    "        \n",
    "    processed_account = convert_date(account_df, 'date')\n",
    "    \n",
    "    # Renaming account attributes\n",
    "    processed_account.loc[processed_account[\"frequency\"]==\"monthly issuance\",\"frequency\"] = \"MI\"\n",
    "    processed_account.loc[processed_account[\"frequency\"]==\"weekly issuance\",\"frequency\"] = \"WI\"\n",
    "    processed_account.loc[processed_account[\"frequency\"]==\"issuance after transaction\",\"frequency\"] = \"IAT\"\n",
    "    \n",
    "    # Transform numerical into categorical\n",
    "    df = pd.get_dummies(processed_account)\n",
    "    \n",
    "    if debug:\n",
    "        print(' > Transformed the categorical frequency column into numerical respective columns')\n",
    "        display(df)\n",
    "        print(' > Since the 3 categories are depedent, we can remove one of them, for removing redundant data')\n",
    "        \n",
    "    df = df.drop(['frequency_IAT'], axis=1)\n",
    "        \n",
    "    if debug:\n",
    "        print(' > Hence, we get the processed accounts dataframe:')\n",
    "        display(df)\n",
    "        print(' > And the features correlation:')\n",
    "        get_df_correlation(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dispostition(disp_df, debug=False):\n",
    "    '''Pre process the dispositions table'''\n",
    "    if debug:\n",
    "        print(' > Raw disposition table representation')\n",
    "        display(disp_df)\n",
    "        print(' > Raw disposition table correlations')\n",
    "        get_df_correlation(disp_df)\n",
    "        \n",
    "    processed_disp = disp_df.copy()\n",
    "    \n",
    "    # Renaming disp attributes\n",
    "    processed_disp.loc[processed_disp[\"type\"]==\"OWNER\",\"type\"] = \"O\"\n",
    "    processed_disp.loc[processed_disp[\"type\"]==\"DISPONENT\",\"type\"] = \"U\"\n",
    "    \n",
    "    # Transform numerical into categorical\n",
    "    df = pd.get_dummies(processed_disp)\n",
    "    \n",
    "    if debug:\n",
    "        print(' > Transformed the categorical type column into numerical respective columns')\n",
    "        display(df)\n",
    "        print(' > Since the 2 categories are depedent, we can remove one of them, for removing redundant data')\n",
    "        get_df_correlation(df)\n",
    "        \n",
    "    # Cannot process further as needs merging with other columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_card(card_df, debug=False):\n",
    "    '''Pre process the credit card table'''\n",
    "    if debug:\n",
    "        print(' > Raw credit card table representation')\n",
    "        display(card_df)\n",
    "        print(' > Raw credit card table correlations')\n",
    "        get_df_correlation(card_df)\n",
    "\n",
    "    processed_card = convert_date(card_df, 'issued')\n",
    "\n",
    "    # Renaming card attributes\n",
    "    processed_card.loc[processed_card[\"type\"]==\"classic\",\"type\"] = \"C\"\n",
    "    processed_card.loc[processed_card[\"type\"]==\"gold\",\"type\"] = \"G\"\n",
    "    processed_card.loc[processed_card[\"type\"]==\"junior\",\"type\"] = \"J\"\n",
    "    \n",
    "    # Transform numerical into categorical & removing useless column\n",
    "    df = pd.get_dummies(processed_card)\n",
    "    df = df.drop(['card_id'], axis=1)\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print(' > Transformed the categorical type column into numerical respective columns')\n",
    "        display(df)\n",
    "        print(' > Since the 2 categories are depedent, we can remove one of them, for removing redundant data')\n",
    "        get_df_correlation(df)\n",
    "        \n",
    "    # Cannot process further as needs merging with other columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_transactions(transactions_df, debug=False):\n",
    "    '''Pre process the transactions table'''\n",
    "    if debug:\n",
    "        print(' > Raw transactions table representation')\n",
    "        display(transactions_df)\n",
    "        print(' > Raw transactions table correlations')\n",
    "        get_df_correlation(transactions_df)\n",
    "        \n",
    "    if debug:\n",
    "        print(' > Null evaluation in transactions rows')\n",
    "        get_null_summary(transactions_df)\n",
    "        \n",
    "    # Removing the null columns & processing data\n",
    "    processed_df = clean_nulls(transactions_df)\n",
    "    processed_df = convert_date(processed_df, 'date')\n",
    "    \n",
    "    # Renaming 'withdrawal in cash' to 'withdrawal'\n",
    "    processed_df.loc[processed_df[\"type\"]==\"withdrawal in cash\",\"type\"] = \"withdrawal\"\n",
    "    \n",
    "    if debug:\n",
    "        display(processed_df['operation'].unique())\n",
    "        display(processed_df['type'].unique())\n",
    "        display(processed_df['k_symbol'].unique())\n",
    "        display(processed_df.sort_values(by=['account_id', 'date'],\n",
    "                                            ascending=[True, False]))\n",
    "\n",
    "    # Aggregatting transaction balances\n",
    "    agg_ballance = processed_df.sort_values(by=['account_id', 'date'],\n",
    "                                            ascending=[True, False])\\\n",
    "                               .groupby(['account_id'])\\\n",
    "                               .agg({\n",
    "                                    'balance': ['mean', 'max', 'min', lambda x: x.iloc[0]]\n",
    "                               })\\\n",
    "                               .reset_index()\n",
    "    agg_ballance.columns = ['account_id', 'balance_mean', 'balance_max', 'balance_min', 'last_ballance']\n",
    "\n",
    "    # Agrregatting credits\n",
    "    agg_credits = processed_df.groupby(['account_id', 'type'])\\\n",
    "                              .agg({\n",
    "                                  'amount': ['mean', 'count', 'max', 'min'],\n",
    "                              })\\\n",
    "                              .reset_index()\n",
    "    agg_credits.columns = ['account_id', 'type', 'credit_mean', 'credit_count', 'credit_max', 'credit_min']\n",
    "    agg_credits = agg_credits[agg_credits['type'] == 'credit']\n",
    "    \n",
    "    # Aggregatting withdrawals\n",
    "    agg_withdrawals = processed_df.groupby(['account_id', 'type'])\\\n",
    "                                  .agg({\n",
    "                                    'amount': ['mean', 'count', 'max', 'min'],\n",
    "                                  })\\\n",
    "                                  .reset_index()\n",
    "    agg_withdrawals.columns = ['account_id', 'type', 'withdrawal_mean', 'withdrawal_count',\n",
    "                           'withdrawal_max', 'withdrawal_min']\n",
    "    agg_withdrawals = agg_withdrawals[agg_withdrawals['type'] == 'withdrawal']\n",
    "\n",
    "    # Aggregatting all the 3 tables into one\n",
    "    df = agg_ballance.merge(agg_credits, on='account_id')\\\n",
    "                          .merge(agg_withdrawals, on='account_id', how='left')\n",
    "    \n",
    "    # Cleaning nulls and useless columns\n",
    "    df = df.drop(['type_x', 'type_y'], axis=1)\n",
    "    df = numerical_imputation(df, 0)\n",
    "    \n",
    "    # Adding extra columns\n",
    "    df['mean_trans_profit'] = df['credit_mean'] - df['withdrawal_mean']\n",
    "\n",
    "    if debug:\n",
    "        print(' > Table after processment of balance, credits and withdrawals')\n",
    "        display(df)\n",
    "        get_null_summary(df)\n",
    "        print(' > And the corresponding correlation matrix')\n",
    "        get_df_correlation(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite pre processment of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compose_dataset(loan_df, account_df, disp_df, card_df, debug=False):\n",
    "    '''Join the different tables and apply feature engineering'''\n",
    "\n",
    "    # Creating formatted copy tables, so I can edit without changing original\n",
    "    processed_loan = convert_date(loan_df, 'date')\n",
    "    processed_disp =\n",
    "    processed_card = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Joining loan table, accounts table, disposition table & card table\n",
    "    df = processed_loan.merge(processed_account.rename(columns={'date': 'account_creation_date'}),\n",
    "                              on='account_id')\\\n",
    "                       .merge(processed_disp, on='account_id')\\\n",
    "                       .merge(processed_card.rename(columns={'type': 'card_type'}),\n",
    "                              on='disp_id', how='left')\n",
    "    \n",
    "    if debug:\n",
    "        print(' > Joint tables analysis')\n",
    "        get_df_correlation(df)\n",
    "    \n",
    "    # Getting loanes age, in months & duration in months as well\n",
    "    df['account_loan_age'] = (df['date'] - df['account_creation_date']).dt.days / 31\n",
    "    df[\"date\"] = pd.to_numeric(df[\"date\"])\n",
    "    df['duration'] = df['duration'] / 31\n",
    "\n",
    "    # Separating categorial features\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Getting the Number of account owners & type of cards related to each account\n",
    "    df_num_owners_and_types = df.groupby(\n",
    "        ['loan_id', 'account_id']\n",
    "    ).agg({\n",
    "        'type_O': ['count'],\n",
    "        'card_type_C': ['sum'],\n",
    "        'card_type_G': ['sum'],\n",
    "        'card_type_J': ['sum']\n",
    "    }).reset_index()\n",
    "    df_num_owners_and_types.columns = ['loan_id', 'acc', 'owners_count', 'C', 'G', 'J']\n",
    "    df_num_owners_and_types = df_num_owners_and_types.drop(['acc'], axis=1)\n",
    "\n",
    "    # Dropping useless columns\n",
    "    df = df.drop(['account_creation_date', 'account_id', 'district_id',\n",
    "                  'frequency_IAT', 'type_U', 'type_O', 'disp_id',\n",
    "                  'client_id', 'card_id', 'issued', 'card_type_C',\n",
    "                  'card_type_G', 'card_type_J'], axis=1)\\\n",
    "           .drop_duplicates()\n",
    "    \n",
    "    # Merging with the aggregattion results\n",
    "    df = df.merge(df_num_owners_and_types, on='loan_id')\n",
    "    df = df.drop(['J'], axis=1)\n",
    "    \n",
    "    # Normalize numerical columns\n",
    "    normalize_columns(df, ['amount', 'payments', 'date', 'monthly_loan',\n",
    "                           'monthly_loan-to-monthly_receiving', 'monthly_only_receiving'])\n",
    "\n",
    "    # Writing loan_id for later association on predictions\n",
    "    utils.write_df_to_csv(\n",
    "        df[['loan_id', 'date', 'amount']],\n",
    "        'dataset', 'ids.csv')\n",
    "    df = df.drop(['loan_id', 'duration', 'num_payments', 'months_of_receiving', 'G'], axis=1)\n",
    "\n",
    "    # Placing status column as last column\n",
    "    return  df[[col for col in df if col not in ['status']] + ['status']]\n",
    "\n",
    "\n",
    "dataset = compose_dataset(loan_df, account_df, disp_df, card_df, debug=True)\n",
    "display(dataset)\n",
    "get_df_correlation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good tutorial for feature engineering:\n",
    "# https://medium.com/datadriveninvestor/a-simple-guide-to-creating-predictive-models-in-python-part-1-8e3ddc3d7008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the resultant table to a final csv\n",
    "utils.write_df_to_csv(dataset, 'dataset', 'preprocessed_data.csv')\n",
    "utils.write_df_to_csv(compose_dataset(loan_test_df, account_df, disp_df, card_test_df),\n",
    "                      'dataset', 'test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
